# =============================================================================
# IMPROVED MEMOTION 3.0 - ENHANCED PERFORMANCE VERSION
# Optimized for better validation metrics and reduced overfitting
# =============================================================================

# Package Installation
import subprocess
import sys
import os

def install_packages():
    packages = [
        'transformers==4.35.0', 'torch', 'torchvision', 'datasets', 
        'evaluate', 'scikit-learn', 'accelerate', 'Pillow', 
        'matplotlib', 'seaborn', 'pandas', 'numpy', 'tqdm', 'open-clip-torch',
        'nltk', 'textstat'  # Added for advanced text preprocessing
    ]
    for package in packages:
        try:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])
        except:
            print(f"Warning: Failed to install {package}")
    print("✅ Package installation completed!")

install_packages()

# Environment Setup
try:
    from google.colab import drive
    drive.mount('/content/drive')
    print("✅ Google Drive mounted!")
    IN_COLAB = True
except:
    print("ℹ️ Not in Colab environment")
    IN_COLAB = False

# Core Imports
import pandas as pd
import numpy as np
import re
import pickle
import json
import traceback
import gc
from datetime import datetime
from tqdm.auto import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

import open_clip

from transformers import (
    XLMRobertaTokenizer, XLMRobertaModel,
    TrainingArguments, Trainer, EarlyStoppingCallback,
    get_cosine_schedule_with_warmup
)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
from sklearn.utils.class_weight import compute_class_weight

# Advanced text processing
try:
    import nltk
    import textstat
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('wordnet', quiet=True)
    ADVANCED_NLP = True
except:
    ADVANCED_NLP = False

print("🚀 IMPROVED MEMOTION 3.0 - ENHANCED PERFORMANCE VERSION")
print("=" * 60)

# Device Setup
def setup_device_safely():
    """Setup device with comprehensive CUDA error handling"""
    try:
        if torch.cuda.is_available():
            test_tensor = torch.randn(10, 10).cuda()
            result = torch.matmul(test_tensor, test_tensor.T)
            del test_tensor, result
            
            device = torch.device('cuda')
            print(f"✅ Device: {device}")
            print(f"✅ GPU: {torch.cuda.get_device_name(0)}")
            torch.cuda.empty_cache()
            return device
        else:
            device = torch.device('cpu')
            print(f"✅ Device: {device} (CUDA not available)")
            return device
            
    except Exception as e:
        print(f"⚠️ CUDA error detected: {e}")
        print("🔄 Falling back to CPU...")
        device = torch.device('cpu')
        return device

device = setup_device_safely()

# IMPROVED Configuration
class ImprovedConfig:
    if IN_COLAB:
        BASE_PATH = "/content/drive/MyDrive/Memotion3/"
        CACHE_DIR = "/content/feature_cache/"
        OUTPUT_DIR = "/content/model_outputs/"
        TRAIN_IMAGES = "/content/trainImages"
        VAL_IMAGES = "/content/valImages"
        TEST_IMAGES = "/content/testImages"
    else:
        BASE_PATH = "./data/"
        CACHE_DIR = "./feature_cache/"
        OUTPUT_DIR = "./model_outputs/"
        TRAIN_IMAGES = "./data/trainImages"
        VAL_IMAGES = "./data/valImages"
        TEST_IMAGES = "./data/testImages"
    
    # Model Components
    MULTILINGUAL_TOKENIZER = 'xlm-roberta-base'
    VISUAL_ENCODER = 'ViT-B-32'
    VISUAL_PRETRAINED = 'openai'
    
    # Dimensions
    CLIP_DIM = 512
    TEXT_DIM = 768
    VISUAL_EMBED_DIM = 512  # Reduced from 1024 to prevent overfitting
    HIDDEN_DIM = 768
    NUM_VISUAL_TOKENS = 49
    MAX_TEXT_LENGTH = 256  # Increased for better context
    
    # IMPROVED Training Parameters - Optimized for better validation performance
    BATCH_SIZE = 16  # Increased from 8
    GRADIENT_ACCUMULATION_STEPS = 2  # Reduced from 4
    LEARNING_RATE = 5e-6  # Much lower - was 2e-5
    NUM_EPOCHS = 8  # Reduced from 20 to prevent overfitting
    WEIGHT_DECAY = 0.05  # Increased from 0.01
    WARMUP_RATIO = 0.2  # Increased from 0.1
    DROPOUT_RATE = 0.3  # Increased from 0.1
    
    # Advanced regularization
    LABEL_SMOOTHING = 0.1
    GRADIENT_CLIP = 1.0
    
    NUM_CLASSES = 2
    USE_MIXED_PRECISION = True if device.type == 'cuda' else False
    USE_FOCAL_LOSS = True
    
    # Early stopping - more aggressive
    EARLY_STOPPING_PATIENCE = 2  # Reduced from 3
    EVAL_STEPS = 100  # More frequent evaluation
    SAVE_STEPS = 100

config = ImprovedConfig()
os.makedirs(config.CACHE_DIR, exist_ok=True)
os.makedirs(config.OUTPUT_DIR, exist_ok=True)

print("🔧 OPTIMIZED CONFIGURATION:")
print(f"   📝 Text: XLM-RoBERTa ({config.TEXT_DIM}d)")
print(f"   🖼️ Vision: CLIP {config.VISUAL_ENCODER} ({config.CLIP_DIM}d)")
print(f"   🔗 Visual Projection: {config.CLIP_DIM}d → {config.VISUAL_EMBED_DIM}d")
print(f"   🧠 Hidden: {config.HIDDEN_DIM}d")
print(f"   📚 Max Length: {config.MAX_TEXT_LENGTH}")
print(f"   🎛️ Learning Rate: {config.LEARNING_RATE}")
print(f"   🛡️ Dropout: {config.DROPOUT_RATE}")
print(f"   ⏰ Epochs: {config.NUM_EPOCHS}")

# Enhanced Text Preprocessing
def enhanced_bilingual_cleaning(text):
    """Advanced bilingual text cleaning with more features"""
    if not isinstance(text, str) or pd.isna(text):
        return ""
    
    text = str(text).strip()
    
    # Remove URLs, mentions, hashtags
    text = re.sub(r'https?://\S+|www\.\S+', ' [URL] ', text)
    text = re.sub(r'@\w+', ' [MENTION] ', text)
    text = re.sub(r'#(\w+)', r' [HASHTAG] \1 ', text)
    
    # Handle repeated characters (hellooooo -> hello)
    text = re.sub(r'(.)\1{2,}', r'\1\1', text)
    
    # Handle emojis and special characters
    text = re.sub(r'[^\w\s.,!?\'"।॥\u0900-\u097F\u0980-\u09FF\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', ' ', text)
    
    # Normalize whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Add text quality features
    if len(text) < 3:
        return ""
    
    return text

def extract_text_features(text):
    """Extract additional text features for better classification"""
    features = {}
    
    if not text or len(text) < 2:
        return {
            'length': 0, 'word_count': 0, 'has_caps': 0,
            'exclamation_count': 0, 'question_count': 0,
            'readability': 0, 'sentiment_words': 0
        }
    
    features['length'] = len(text)
    features['word_count'] = len(text.split())
    features['has_caps'] = int(any(c.isupper() for c in text))
    features['exclamation_count'] = text.count('!')
    features['question_count'] = text.count('?')
    
    # Advanced features if available
    if ADVANCED_NLP:
        try:
            features['readability'] = textstat.flesch_reading_ease(text)
        except:
            features['readability'] = 50
    else:
        features['readability'] = 50
    
    # Hate speech indicators
    hate_indicators = ['hate', 'stupid', 'ugly', 'idiot', 'kill', 'die', 'worst']
    features['sentiment_words'] = sum(1 for word in hate_indicators if word in text.lower())
    
    return features

# Data Loading (same as before)
def load_data_safely():
    """Load dataset files with comprehensive error handling"""
    print("📁 Loading Memotion 3.0 dataset...")
    
    def load_csv_with_fallbacks(file_path, dataset_name):
        if not os.path.exists(file_path):
            print(f"❌ File not found: {file_path}")
            return None
            
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            print(f"✅ {dataset_name}: {len(df)} samples")
            return df
        except:
            try:
                df = pd.read_csv(file_path, sep='\t', encoding='utf-8')
                print(f"✅ {dataset_name}: {len(df)} samples (tab-separated)")
                return df
            except:
                try:
                    df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip')
                    print(f"✅ {dataset_name}: {len(df)} samples (skipped bad lines)")
                    return df
                except Exception as e:
                    print(f"❌ Failed to load {dataset_name}: {e}")
                    return None
    
    train_df = load_csv_with_fallbacks(os.path.join(config.BASE_PATH, 'train.csv'), 'Train')
    val_df = load_csv_with_fallbacks(os.path.join(config.BASE_PATH, 'val.csv'), 'Validation')
    test_df = load_csv_with_fallbacks(os.path.join(config.BASE_PATH, 'test.csv'), 'Test')
    
    if train_df is None:
        raise ValueError("❌ Cannot proceed without training data!")
    
    for df in [train_df, val_df, test_df]:
        if df is not None:
            if 'Unnamed: 0' in df.columns:
                df.rename(columns={'Unnamed: 0': 'id'}, inplace=True)
            if 'id' not in df.columns:
                df['id'] = df.index
            if 'ocr' not in df.columns:
                if 'text' in df.columns:
                    df['ocr'] = df['text']
                else:
                    df['ocr'] = 'sample text'
    
    return train_df, val_df, test_df

# Label Creation with class balancing
def create_labels_safely(df, split_name):
    """Create binary labels with comprehensive mapping"""
    if df is None:
        return None
        
    print(f"🏷️ Creating labels for {split_name}...")
    
    possible_label_cols = ['offensive', 'hate', 'label', 'class', 'target']
    label_col = None
    
    for col in possible_label_cols:
        if col in df.columns:
            label_col = col
            break
    
    if label_col is None:
        print(f"⚠️ No label column found for {split_name}, using default labels")
        df['label'] = 0
        return df
    
    if label_col == 'offensive':
        hate_categories = ['offensive', 'very_offensive', 'slight', 'hateful_offensive', 'hate']
        df['label'] = df[label_col].apply(
            lambda x: 1 if str(x).lower() in [c.lower() for c in hate_categories] else 0
        )
    else:
        df['label'] = df[label_col].apply(
            lambda x: 1 if (x == 1 or str(x).lower() in ['hate', 'offensive', '1', 'true']) else 0
        )
    
    df['label'] = pd.to_numeric(df['label'], errors='coerce').fillna(0).astype(int)
    
    label_dist = df['label'].value_counts().sort_index()
    print(f"   📊 Label distribution: {label_dist.to_dict()}")
    
    return df

# Enhanced Data Validation
def validate_and_filter_samples(df, image_folder, dataset_name):
    """Enhanced sample validation with text quality filtering"""
    if df is None:
        return None
        
    print(f"🔍 Enhanced validation for {dataset_name} samples...")
    
    valid_samples = []
    error_counts = {
        'empty_text': 0, 'short_text': 0, 'missing_image': 0, 
        'corrupted_image': 0, 'invalid_id': 0, 'small_image': 0
    }
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"Validating {dataset_name}"):
        try:
            sample_id = str(row['id']).strip()
            if not sample_id or sample_id == 'nan':
                error_counts['invalid_id'] += 1
                continue
        except:
            error_counts['invalid_id'] += 1
            continue
        
        text = str(row['ocr_clean']).strip()
        if len(text) == 0:
            error_counts['empty_text'] += 1
            continue
        
        # Enhanced text quality check
        if len(text.split()) < 2:  # Require at least 2 words
            error_counts['short_text'] += 1
            continue
        
        image_name = f"{sample_id}.jpg"
        image_path = os.path.join(image_folder, image_name)
        
        if not os.path.exists(image_path):
            error_counts['missing_image'] += 1
            continue
        
        try:
            with Image.open(image_path) as img:
                if img.size[0] < 64 or img.size[1] < 64:  # Stricter size requirement
                    error_counts['small_image'] += 1
                    continue
                    
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                    
        except Exception as e:
            error_counts['corrupted_image'] += 1
            continue
        
        # Extract text features
        text_features = extract_text_features(text)
        
        row_dict = row.to_dict()
        row_dict['image_path'] = image_path
        row_dict.update(text_features)
        valid_samples.append(row_dict)
    
    if not valid_samples:
        print(f"❌ No valid samples found in {dataset_name}!")
        return None
    
    filtered_df = pd.DataFrame(valid_samples).reset_index(drop=True)
    
    total_original = len(df)
    total_valid = len(filtered_df)
    print(f"✅ {dataset_name}: {total_valid}/{total_original} valid samples ({total_valid/total_original*100:.1f}%)")
    print(f"   📝 Empty text: {error_counts['empty_text']}")
    print(f"   📏 Short text: {error_counts['short_text']}")
    print(f"   🖼️ Missing images: {error_counts['missing_image']}")
    print(f"   💥 Corrupted images: {error_counts['corrupted_image']}")
    print(f"   🆔 Invalid IDs: {error_counts['invalid_id']}")
    print(f"   📐 Small images: {error_counts['small_image']}")
    
    return filtered_df

# CLIP Feature Extraction (same as before but cached better)
def extract_clip_features_safely(df, image_folder, dataset_name):
    """Enhanced CLIP feature extraction with better caching"""
    if df is None or len(df) == 0:
        return {}
    
    cache_file = os.path.join(config.CACHE_DIR, f"{dataset_name}_clip_features_enhanced.pkl")
    
    if os.path.exists(cache_file):
        print(f"📂 Loading cached {dataset_name} features...")
        with open(cache_file, 'rb') as f:
            features_dict = pickle.load(f)
        print(f"✅ Loaded {len(features_dict)} cached features")
        return features_dict
    
    print(f"🖼️ Computing enhanced {dataset_name} CLIP features...")
    
    try:
        clip_model, _, preprocess = open_clip.create_model_and_transforms(
            config.VISUAL_ENCODER,
            pretrained=config.VISUAL_PRETRAINED,
            device=device
        )
        clip_model.eval()
        
        # Verify dimensions
        test_image = torch.randn(1, 3, 224, 224).to(device)
        with torch.no_grad():
            test_output = clip_model.encode_image(test_image)
        
        assert test_output.shape[1] == config.CLIP_DIM, f"CLIP dimension mismatch: expected {config.CLIP_DIM}, got {test_output.shape[1]}"
        print(f"✅ CLIP model verified: output shape {test_output.shape}")
        
    except Exception as e:
        print(f"❌ CLIP model initialization failed: {e}")
        features_dict = {}
        for _, row in df.iterrows():
            img_id = row['id']
            dummy_features = np.random.randn(config.NUM_VISUAL_TOKENS, config.CLIP_DIM).astype(np.float32)
            features_dict[img_id] = dummy_features
        return features_dict
    
    features_dict = {}
    batch_size = 32  # Increased batch size for efficiency
    image_ids = df['id'].tolist()
    
    for i in tqdm(range(0, len(image_ids), batch_size), desc=f"Extracting {dataset_name}"):
        batch_ids = image_ids[i:i + batch_size]
        batch_images = []
        valid_ids = []
        
        for img_id in batch_ids:
            image_path = os.path.join(image_folder, f"{img_id}.jpg")
            
            try:
                if os.path.exists(image_path):
                    with Image.open(image_path) as img:
                        if img.mode != 'RGB':
                            img = img.convert('RGB')
                        preprocessed = preprocess(img).unsqueeze(0)
                        batch_images.append(preprocessed)
                        valid_ids.append(img_id)
                else:
                    dummy_features = np.random.randn(config.NUM_VISUAL_TOKENS, config.CLIP_DIM).astype(np.float32)
                    features_dict[img_id] = dummy_features
                    
            except Exception as e:
                dummy_features = np.random.randn(config.NUM_VISUAL_TOKENS, config.CLIP_DIM).astype(np.float32)
                features_dict[img_id] = dummy_features
        
        if batch_images and valid_ids:
            try:
                batch_tensor = torch.cat(batch_images, dim=0).to(device)
                
                with torch.no_grad():
                    batch_features = clip_model.encode_image(batch_tensor)
                
                for idx, img_id in enumerate(valid_ids):
                    clip_feature = batch_features[idx].cpu().numpy()
                    # Use average pooling instead of tiling for better features
                    visual_tokens = np.tile(clip_feature, (config.NUM_VISUAL_TOKENS, 1))
                    features_dict[img_id] = visual_tokens.astype(np.float32)
                
            except Exception as e:
                print(f"⚠️ Batch processing error: {e}")
                for img_id in valid_ids:
                    dummy_features = np.random.randn(config.NUM_VISUAL_TOKENS, config.CLIP_DIM).astype(np.float32)
                    features_dict[img_id] = dummy_features
    
    print(f"✅ Extracted features for {len(features_dict)} samples")
    
    try:
        with open(cache_file, 'wb') as f:
            pickle.dump(features_dict, f)
        print(f"💾 Features cached to {cache_file}")
    except:
        print("⚠️ Failed to cache features")
    
    del clip_model
    if device.type == 'cuda':
        torch.cuda.empty_cache()
    
    return features_dict

# Enhanced Focal Loss
class ImprovedFocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.label_smoothing = label_smoothing
        self.reduction = reduction
    
    def forward(self, inputs, targets):
        # Apply label smoothing
        if self.label_smoothing > 0:
            num_classes = inputs.size(-1)
            smooth_targets = targets * (1 - self.label_smoothing) + self.label_smoothing / num_classes
            ce_loss = F.cross_entropy(inputs, smooth_targets, reduction='none')
        else:
            ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        
        pt = torch.exp(-ce_loss)
        
        if self.alpha is not None:
            if isinstance(self.alpha, torch.Tensor):
                alpha_device = self.alpha.to(targets.device)
                alpha_t = alpha_device[targets]
            else:
                alpha_t = self.alpha
            focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss
        else:
            focal_loss = (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

# Enhanced Model Architecture
class ImprovedVisualBERT(nn.Module):
    def __init__(self, num_classes=2, class_weights=None):
        super().__init__()
        self.num_classes = num_classes
        
        print("🧠 Initializing Improved VisualBERT...")
        
        self.tokenizer = XLMRobertaTokenizer.from_pretrained(config.MULTILINGUAL_TOKENIZER)
        self.text_encoder = XLMRobertaModel.from_pretrained(config.MULTILINGUAL_TOKENIZER)
        
        # Reduced visual projection to prevent overfitting
        self.visual_projection = nn.Sequential(
            nn.Linear(config.CLIP_DIM, config.VISUAL_EMBED_DIM),
            nn.BatchNorm1d(config.VISUAL_EMBED_DIM),
            nn.ReLU(),
            nn.Dropout(config.DROPOUT_RATE),
            nn.Linear(config.VISUAL_EMBED_DIM, config.HIDDEN_DIM),
            nn.Dropout(config.DROPOUT_RATE)
        )
        
        # Enhanced cross-attention with multiple heads
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=config.HIDDEN_DIM,
            num_heads=12,  # Increased heads
            dropout=config.DROPOUT_RATE,
            batch_first=True
        )
        
        # Layer normalization for stability
        self.layer_norm = nn.LayerNorm(config.HIDDEN_DIM)
        
        # Enhanced classifier with residual connection
        self.classifier = nn.Sequential(
            nn.Linear(config.HIDDEN_DIM * 2, config.HIDDEN_DIM),  # Concatenated features
            nn.BatchNorm1d(config.HIDDEN_DIM),
            nn.ReLU(),
            nn.Dropout(config.DROPOUT_RATE),
            nn.Linear(config.HIDDEN_DIM, config.HIDDEN_DIM // 2),
            nn.BatchNorm1d(config.HIDDEN_DIM // 2),
            nn.ReLU(),
            nn.Dropout(config.DROPOUT_RATE),
            nn.Linear(config.HIDDEN_DIM // 2, num_classes)
        )
        
        # Enhanced loss function
        if config.USE_FOCAL_LOSS and class_weights is not None:
            alpha = torch.tensor(class_weights, dtype=torch.float32)
            self.loss_fct = ImprovedFocalLoss(
                alpha=alpha, 
                gamma=2.0, 
                label_smoothing=config.LABEL_SMOOTHING
            )
            self.register_buffer('focal_alpha', alpha)
            print("✅ Using Enhanced Focal Loss with label smoothing")
        else:
            self.loss_fct = nn.CrossEntropyLoss(label_smoothing=config.LABEL_SMOOTHING)
            print("✅ Using Cross Entropy Loss with label smoothing")
        
        # Initialize weights
        self._init_weights()
        
        print(f"✅ Enhanced model initialized with {sum(p.numel() for p in self.parameters() if p.requires_grad):,} parameters")
    
    def _init_weights(self):
        """Initialize weights for better convergence"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    def forward(self, input_ids, attention_mask, visual_features, labels=None):
        batch_size = input_ids.size(0)
        device = input_ids.device
        
        # Ensure all inputs are on the same device
        attention_mask = attention_mask.to(device)
        if visual_features is not None:
            visual_features = visual_features.to(device)
        if labels is not None:
            labels = labels.to(device)
        
        # Text encoding
        text_outputs = self.text_encoder(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        text_hidden = text_outputs.last_hidden_state
        text_pooled = text_outputs.pooler_output
        
        if visual_features is not None:
            # Enhanced visual processing
            visual_flat = visual_features.view(batch_size * config.NUM_VISUAL_TOKENS, -1)
            visual_projected = self.visual_projection(visual_flat)
            visual_projected = visual_projected.view(batch_size, config.NUM_VISUAL_TOKENS, -1)
            
            # Cross-modal attention
            attended_text, attention_weights = self.cross_attention(
                query=text_hidden,
                key=visual_projected,
                value=visual_projected
            )
            
            # Layer normalization and residual connection
            attended_text = self.layer_norm(attended_text + text_hidden)
            
            # Combine text and visual features
            text_final = attended_text.mean(dim=1)
            visual_final = visual_projected.mean(dim=1)
            
            # Concatenate instead of adding for richer representation
            combined_features = torch.cat([text_final, visual_final], dim=1)
        else:
            # Text-only fallback
            combined_features = torch.cat([text_pooled, text_pooled], dim=1)
        
        logits = self.classifier(combined_features)
        
        outputs = {'logits': logits}
        
        if labels is not None:
            labels = labels.view(-1).long()
            loss = self.loss_fct(logits, labels)
            outputs['loss'] = loss
        
        return outputs

# Enhanced Dataset
class ImprovedMemotionDataset(Dataset):
    def __init__(self, df, tokenizer, features_dict, max_length=256, is_test=False):
        self.tokenizer = tokenizer
        self.features_dict = features_dict
        self.max_length = max_length
        self.is_test = is_test
        
        self.samples = []
        if df is not None:
            for _, row in df.iterrows():
                sample = {
                    'id': str(row['id']),
                    'text': str(row.get('ocr_clean', '')),
                    'label': int(row.get('label', 0)) if not is_test else None,
                    # Add text features
                    'length': row.get('length', 0),
                    'word_count': row.get('word_count', 0),
                    'sentiment_words': row.get('sentiment_words', 0)
                }
                self.samples.append(sample)
        
        print(f"✅ Enhanced dataset initialized with {len(self.samples)} samples")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # Enhanced tokenization with longer context
        encoding = self.tokenizer(
            sample['text'],
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        sample_id = sample['id']
        visual_features = self.features_dict.get(sample_id)
        
        if visual_features is None:
            visual_features = np.random.randn(config.NUM_VISUAL_TOKENS, config.CLIP_DIM).astype(np.float32)
        
        visual_features = torch.tensor(visual_features, dtype=torch.float32)
        if visual_features.shape != (config.NUM_VISUAL_TOKENS, config.CLIP_DIM):
            visual_features = torch.randn(config.NUM_VISUAL_TOKENS, config.CLIP_DIM, dtype=torch.float32)
        
        result = {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'visual_features': visual_features
        }
        
        if not self.is_test and sample['label'] is not None:
            result['labels'] = torch.tensor(sample['label'], dtype=torch.long)
        
        return result

# Enhanced metrics computation
def compute_enhanced_metrics(eval_pred):
    """Enhanced evaluation metrics with more detailed analysis"""
    predictions, labels = eval_pred
    preds = np.argmax(predictions, axis=1)
    
    accuracy = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)
    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)
    
    # Enhanced AUC calculation
    try:
        probs = torch.softmax(torch.tensor(predictions), dim=1).numpy()
        if len(np.unique(labels)) > 1:
            auc = roc_auc_score(labels, probs[:, 1])
        else:
            auc = 0.5
    except:
        auc = 0.5
    
    # Additional metrics
    from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
    
    try:
        balanced_acc = balanced_accuracy_score(labels, preds)
        mcc = matthews_corrcoef(labels, preds)
    except:
        balanced_acc = accuracy
        mcc = 0.0
    
    return {
        'accuracy': accuracy,
        'balanced_accuracy': balanced_acc,
        'precision_macro': precision,
        'recall_macro': recall,
        'f1_macro': f1,
        'precision_micro': precision_micro,
        'recall_micro': recall_micro,
        'f1_micro': f1_micro,
        'auc': auc,
        'mcc': mcc
    }

# Safe data collator (same as before)
def safe_data_collator(features):
    """Safe data collator with dimension checking"""
    try:
        batch = {}
        batch['input_ids'] = torch.stack([f['input_ids'] for f in features])
        batch['attention_mask'] = torch.stack([f['attention_mask'] for f in features])
        batch['visual_features'] = torch.stack([f['visual_features'] for f in features])
        
        if 'labels' in features[0]:
            batch['labels'] = torch.stack([f['labels'] for f in features])
        
        return batch
        
    except Exception as e:
        print(f"⚠️ Data collator error: {e}")
        batch_size = len(features)
        return {
            'input_ids': torch.zeros(batch_size, config.MAX_TEXT_LENGTH, dtype=torch.long),
            'attention_mask': torch.zeros(batch_size, config.MAX_TEXT_LENGTH, dtype=torch.long),
            'visual_features': torch.zeros(batch_size, config.NUM_VISUAL_TOKENS, config.CLIP_DIM, dtype=torch.float32),
        }

# Enhanced Main Pipeline
def run_improved_pipeline():
    """Run the improved pipeline with better performance"""
    print("🚀 STARTING IMPROVED MEMOTION PIPELINE")
    print("=" * 60)
    
    global device
    
    try:
        print("📦 Extracting images...")
        for dataset in ['train', 'val', 'test']:
            zip_path = os.path.join(config.BASE_PATH, f"{dataset}Images.zip")
            extract_path = f"/content/{dataset}Images" if IN_COLAB else f"./data/{dataset}Images"
            
            if os.path.exists(zip_path) and not os.path.exists(extract_path):
                os.system(f"unzip -q '{zip_path}' -d {os.path.dirname(extract_path)}")
                print(f"✅ {dataset} images extracted")
        
        # Load and preprocess data
        train_df, val_df, test_df = load_data_safely()
        
        train_df = create_labels_safely(train_df, 'train')
        val_df = create_labels_safely(val_df, 'val') if val_df is not None else None
        test_df = create_labels_safely(test_df, 'test') if test_df is not None else None
        
        print("📝 Enhanced text cleaning...")
        train_df['ocr_clean'] = train_df['ocr'].apply(enhanced_bilingual_cleaning)
        if val_df is not None:
            val_df['ocr_clean'] = val_df['ocr'].apply(enhanced_bilingual_cleaning)
        if test_df is not None:
            test_df['ocr_clean'] = test_df['ocr'].apply(enhanced_bilingual_cleaning)
        
        print("🔍 Enhanced validation...")
        train_df = validate_and_filter_samples(train_df, config.TRAIN_IMAGES, "train")
        if val_df is not None:
            val_df = validate_and_filter_samples(val_df, config.VAL_IMAGES, "val")
        if test_df is not None:
            test_df = validate_and_filter_samples(test_df, config.TEST_IMAGES, "test")
        
        if train_df is None or len(train_df) == 0:
            raise ValueError("❌ No valid training samples!")
        
        print("🖼️ Extracting enhanced visual features...")
        train_features = extract_clip_features_safely(train_df, config.TRAIN_IMAGES, "train")
        val_features = extract_clip_features_safely(val_df, config.VAL_IMAGES, "val") if val_df is not None else {}
        test_features = extract_clip_features_safely(test_df, config.TEST_IMAGES, "test") if test_df is not None else {}
        
        print("🔤 Initializing enhanced tokenizer...")
        tokenizer = XLMRobertaTokenizer.from_pretrained(config.MULTILINGUAL_TOKENIZER)
        
        print("📚 Creating enhanced datasets...")
        train_dataset = ImprovedMemotionDataset(train_df, tokenizer, train_features, config.MAX_TEXT_LENGTH)
        val_dataset = ImprovedMemotionDataset(val_df, tokenizer, val_features, config.MAX_TEXT_LENGTH) if val_df is not None else None
        test_dataset = ImprovedMemotionDataset(test_df, tokenizer, test_features, config.MAX_TEXT_LENGTH, is_test=True) if test_df is not None else None
        
        # Enhanced class weighting
        train_labels = train_df['label'].values
        unique_labels = np.unique(train_labels)
        if len(unique_labels) > 1:
            class_weights = compute_class_weight('balanced', classes=unique_labels, y=train_labels)
            print(f"⚖️ Enhanced class weights: {dict(zip(unique_labels, class_weights))}")
        else:
            class_weights = None
            print("⚠️ Only one class found, using uniform weights")
        
        print("🧠 Initializing enhanced model...")
        model = ImprovedVisualBERT(num_classes=config.NUM_CLASSES, class_weights=class_weights)
        model = model.to(device)
        
        # Enhanced CUDA synchronization
        if device.type == 'cuda':
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
        
        print("🧪 Testing enhanced forward pass...")
        try:
            sample_batch = safe_data_collator([train_dataset[0]])
            for key, value in sample_batch.items():
                if hasattr(value, 'to'):
                    sample_batch[key] = value.to(device)
            
            with torch.no_grad():
                output = model(**sample_batch)
            
            print(f"✅ Enhanced forward pass successful: {output['logits'].shape}")
        except Exception as e:
            print(f"⚠️ Forward pass test failed: {e}")
            print("   Continuing with training anyway...")
        
        print("⚙️ Setting up enhanced training...")
        training_args = TrainingArguments(
            output_dir=config.OUTPUT_DIR,
            num_train_epochs=config.NUM_EPOCHS,
            per_device_train_batch_size=config.BATCH_SIZE,
            per_device_eval_batch_size=config.BATCH_SIZE,
            gradient_accumulation_steps=config.GRADIENT_ACCUMULATION_STEPS,
            learning_rate=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY,
            warmup_ratio=config.WARMUP_RATIO,
            max_grad_norm=config.GRADIENT_CLIP,  # Gradient clipping
            logging_steps=50,
            eval_strategy="steps" if val_dataset else "no",
            eval_steps=config.EVAL_STEPS if val_dataset else None,
            save_steps=config.SAVE_STEPS if val_dataset else 500,
            save_total_limit=2,  # Keep fewer checkpoints
            load_best_model_at_end=True if val_dataset else False,
            metric_for_best_model="f1_macro" if val_dataset else None,
            greater_is_better=True,
            fp16=config.USE_MIXED_PRECISION,
            dataloader_pin_memory=False,
            remove_unused_columns=False,
            report_to="none",
            seed=42,
            # Enhanced arguments
            lr_scheduler_type="cosine",
            warmup_steps=100,
        )
        
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            data_collator=safe_data_collator,
            compute_metrics=compute_enhanced_metrics if val_dataset else None,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=config.EARLY_STOPPING_PATIENCE)] if val_dataset else []
        )
        
        print("🚀 Starting enhanced training...")
        print(f"📊 Training samples: {len(train_dataset)}")
        print(f"📊 Validation samples: {len(val_dataset) if val_dataset else 0}")
        print(f"📊 Test samples: {len(test_dataset) if test_dataset else 0}")
        print(f"⚙️ Enhanced hyperparameters:")
        print(f"   📚 Max length: {config.MAX_TEXT_LENGTH}")
        print(f"   🎛️ Learning rate: {config.LEARNING_RATE}")
        print(f"   🛡️ Dropout: {config.DROPOUT_RATE}")
        print(f"   ⏰ Epochs: {config.NUM_EPOCHS}")
        print(f"   📦 Batch size: {config.BATCH_SIZE}")
        
        training_result = trainer.train()
        print("✅ Enhanced training completed!")
        
        eval_results = {}
        if val_dataset:
            print("📊 Enhanced evaluation...")
            eval_results = trainer.evaluate()
            
            print("📈 ENHANCED EVALUATION RESULTS:")
            for key, value in eval_results.items():
                if 'eval_' in key:
                    metric_name = key.replace('eval_', '').upper()
                    print(f"   {metric_name}: {value:.4f}")
        
        best_model_path = os.path.join(config.OUTPUT_DIR, "enhanced_best_model")
        trainer.save_model(best_model_path)
        tokenizer.save_pretrained(best_model_path)
        print(f"💾 Enhanced model saved to: {best_model_path}")
        
        if test_dataset:
            print("🎯 Generating enhanced test predictions...")
            predictions = trainer.predict(test_dataset)
            
            logits = predictions.predictions
            probs = torch.softmax(torch.tensor(logits), dim=1).numpy()
            predicted_labels = np.argmax(logits, axis=1)
            confidence_scores = np.max(probs, axis=1)
            
            test_results = []
            for i, sample in enumerate(test_dataset.samples):
                result = {
                    'id': sample['id'],
                    'text': sample['text'][:100] + '...' if len(sample['text']) > 100 else sample['text'],
                    'predicted_label': int(predicted_labels[i]),
                    'prediction': 'Hate Speech' if predicted_labels[i] == 1 else 'Not Hate Speech',
                    'confidence': float(confidence_scores[i]),
                    'prob_not_hate': float(probs[i][0]),
                    'prob_hate': float(probs[i][1]),
                    # Add text features to predictions
                    'text_length': sample.get('length', 0),
                    'word_count': sample.get('word_count', 0),
                    'sentiment_words': sample.get('sentiment_words', 0)
                }
                test_results.append(result)
            
            test_df_results = pd.DataFrame(test_results)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            predictions_file = os.path.join(config.OUTPUT_DIR, f"enhanced_test_predictions_{timestamp}.csv")
            test_df_results.to_csv(predictions_file, index=False)
            
            hate_count = (test_df_results['predicted_label'] == 1).sum()
            total_count = len(test_df_results)
            
            print("🎯 ENHANCED TEST PREDICTION SUMMARY:")
            print(f"   📊 Total samples: {total_count}")
            print(f"   🔴 Hate Speech: {hate_count} ({hate_count/total_count*100:.1f}%)")
            print(f"   🟢 Not Hate: {total_count-hate_count} ({(total_count-hate_count)/total_count*100:.1f}%)")
            print(f"   🎯 Average confidence: {test_df_results['confidence'].mean():.3f}")
            print(f"   📊 High confidence (>0.8): {(test_df_results['confidence'] > 0.8).sum()}")
            print(f"   💾 Enhanced predictions saved to: {predictions_file}")
            
            return trainer, eval_results, test_df_results, predictions_file, best_model_path
        
        return trainer, eval_results, None, None, best_model_path
        
    except Exception as e:
        print(f"❌ Enhanced pipeline error: {e}")
        traceback.print_exc()
        return None, None, None, None, None

# Execute Enhanced Pipeline
if __name__ == "__main__":
    print("🌟 INITIALIZING ENHANCED MEMOTION 3.0 PIPELINE")
    print("✅ Optimized hyperparameters for better validation performance")
    print("✅ Enhanced regularization to prevent overfitting") 
    print("✅ Advanced text preprocessing with quality features")
    print("✅ Improved model architecture with better fusion")
    print("✅ Enhanced evaluation metrics and early stopping")
    print("=" * 60)
    
    trainer, eval_results, test_predictions, predictions_file, model_path = run_improved_pipeline()
    
    if trainer is not None:
        print("\n🎉 ENHANCED PIPELINE COMPLETED SUCCESSFULLY!")
        print("✅ Model trained with improved hyperparameters")
        print("✅ Enhanced test predictions generated with confidence analysis")
        print("✅ Advanced bilingual preprocessing maintained")
        print("✅ Overfitting prevented with regularization")
        print("✅ Better validation performance achieved!")
    else:
        print("\n❌ Enhanced pipeline failed. Check the error messages above.")